Function Calling

Function calling, also known as tool use or function invocation, is a capability that allows Large Language Models to interact with external systems by generating structured API calls based on natural language requests. Instead of only producing text responses, function-calling-enabled LLMs can decide when to invoke predefined functions, extract appropriate parameters from user input, and integrate function results into their responses.

The mechanism works by providing the LLM with function schemas (typically in JSON format) that describe available functions, their parameters, types, and descriptions. When a user request requires external data or actions, the model generates a structured function call with extracted arguments rather than a text response. The application executes this function, retrieves results, and feeds them back to the LLM, which then formulates a natural language response incorporating the data. This creates a ReAct (Reasoning and Acting) loop where the model alternates between reasoning about what to do and taking actions through function calls.

Function calling is foundational for building agentic AI systems that go beyond conversation to accomplish real-world tasks. Applications include querying databases, calling APIs for real-time information (weather, stock prices), controlling smart home devices, performing calculations, and executing business logic. It enables conversational AI to be truly interactive and grounded in external reality rather than limited to the model's training data. Modern frameworks like LangChain, Semantic Kernel, and native support in OpenAI and Anthropic APIs have standardized function calling patterns, making it accessible for production applications.
